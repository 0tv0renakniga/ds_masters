{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9890aaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scotty/venvs/ucsd/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/scotty/venvs/ucsd/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/scotty/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [02:22<00:00, 722kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy: 0.9542\n",
      "k-NN (k=1) Test Accuracy: 0.9673\n",
      "k-NN (k=3) Test Accuracy: 0.9542\n",
      "k-NN (k=5) Test Accuracy: 0.9608\n",
      "\n",
      "Summary Table (for LaTeX):\n",
      "classifier\ttest_accuracy\n",
      "logistic regression\t0.9542\n",
      "k-NN (k=1)\t0.9673\n",
      "k-NN (k=3)\t0.9542\n",
      "k-NN (k=5)\t0.9608\n"
     ]
    }
   ],
   "source": [
    "# Ants vs Bees Classification Experiments\n",
    "# ---------------------------------------\n",
    "# This script follows the steps in HW10 Q6, using the provided code as a base.\n",
    "# It visualizes an original and normalized image, extracts ResNet50 features,\n",
    "# trains a logistic regression classifier, and evaluates k-NN classifiers.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 1. Data Preparation and Visualization\n",
    "\n",
    "# Paths\n",
    "data_dir = './hymenoptera_data'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "# Define transforms for normalization (as in the notebook)\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Pick an image from the training directory (original and normalized)\n",
    "sample_class = class_names[0]  # 'ants' or 'bees'\n",
    "sample_class_dir = os.path.join(train_dir, sample_class)\n",
    "sample_img_name = os.listdir(sample_class_dir)[0]\n",
    "sample_img_path = os.path.join(sample_class_dir, sample_img_name)\n",
    "\n",
    "# Load original image\n",
    "original_img = Image.open(sample_img_path).convert('RGB')\n",
    "\n",
    "# Apply normalization transform\n",
    "normalized_img_tensor = data_transforms['train'](original_img)\n",
    "# Undo normalization for display\n",
    "def unnormalize(tensor):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = tensor.numpy().transpose((1, 2, 0))\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "normalized_img_disp = unnormalize(normalized_img_tensor)\n",
    "\n",
    "# Save comparison figure\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_img)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(normalized_img_disp)\n",
    "plt.title('Normalized Image')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('q6_image_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Feature Extraction with ResNet50\n",
    "\n",
    "# Load pre-trained ResNet50 and remove the final classification layer\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "modules = list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "resnet50.eval()\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Helper to extract features for a dataset\n",
    "def extract_features(dataset):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16)\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            outputs = resnet50(inputs)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "            if len(outputs.shape) == 1:\n",
    "                outputs = outputs.unsqueeze(0)\n",
    "            features.append(outputs.numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    X = np.vstack(features)\n",
    "    y = np.hstack(labels)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = extract_features(image_datasets['train'])\n",
    "X_test, y_test = extract_features(image_datasets['val'])\n",
    "\n",
    "# 3. Logistic Regression Classifier\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear', random_state=0, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_lr = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Test Accuracy: {acc_lr:.4f}\")\n",
    "\n",
    "# 4. k-Nearest Neighbor Classifier\n",
    "\n",
    "knn_accuracies = {}\n",
    "for k in [1, 3, 5]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, algorithm='kd_tree')\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    knn_accuracies[k] = acc_knn\n",
    "    print(f\"k-NN (k={k}) Test Accuracy: {acc_knn:.4f}\")\n",
    "\n",
    "# 5. Save results for LaTeX table\n",
    "with open('q6_results.txt', 'w') as f:\n",
    "    f.write(\"classifier\\ttest_accuracy\\n\")\n",
    "    f.write(f\"logistic regression\\t{acc_lr:.4f}\\n\")\n",
    "    for k in [1, 3, 5]:\n",
    "        f.write(f\"k-NN (k={k})\\t{knn_accuracies[k]:.4f}\\n\")\n",
    "\n",
    "# 6. Print summary for manual LaTeX table entry\n",
    "print(\"\\nSummary Table (for LaTeX):\")\n",
    "print(\"classifier\\ttest_accuracy\")\n",
    "print(f\"logistic regression\\t{acc_lr:.4f}\")\n",
    "for k in [1, 3, 5]:\n",
    "    print(f\"k-NN (k={k})\\t{knn_accuracies[k]:.4f}\")\n",
    "\n",
    "# End of script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Distinguishing ants from bees</font>\n",
    "\n",
    "This notebook builds a classifier that distinguishes between images of ants and bees. The classifier has three parts to it:\n",
    "- The images are of varying sizes. So first, they are all normalized to a fixed size.\n",
    "- Then they are run through a pre-trained computer vision neural net, ResNet50, that produces a 2048-dimensional representation\n",
    "- Finally, a logistic regression classifier is built on top of this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Various includes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Torchvision stuff\n",
    "from torchvision import datasets, models, transforms\n",
    "# sklearn stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Loading Dataset</font>\n",
    "\n",
    "For both the train and test data, the images need to be normalized to the particular size, 224x224x3, that is required by the ResNet50 network that we will apply to them. This is achieved by a series of transforms.\n",
    "\n",
    "- The (normalized) training set is in image_datasets['train']\n",
    "- The (normalized) test set is in image_datasets['val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Look at the classes and data set sizes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>Print a sample (transformed) image</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 200\n",
    "[itemx,itemy] = image_datasets['train'].__getitem__(item)\n",
    "print(\"Label: {}\\n\".format(class_names[itemy]))\n",
    "plt.imshow(itemx.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Load pre-trained ResNet50</font>\n",
    "\n",
    "Torch has a bunch of pre-trained nets for computer vision. Let's try out one of them: ResNet50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained = True)\n",
    "modules = list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Extract ResNet features from dataset</font>\n",
    "\n",
    "We'll use ResNet to produce a 2048-dimensional representation for each image.\n",
    "\n",
    "The resulting training set will be in the Numpy arrays (X_train, y_train) and the test set will be in the Numpy arrays (X_test, y_test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x])\n",
    "              for x in ['train', 'val']}\n",
    "for batch,data in enumerate(dataloaders['train']):\n",
    "    if batch==0:\n",
    "        X_train = torch.squeeze(resnet50(data[0])).numpy()\n",
    "        y_train = data[1].numpy()\n",
    "    else:\n",
    "        X_train = np.vstack((X_train,torch.squeeze(resnet50(data[0])).numpy()))\n",
    "        y_train = np.hstack((y_train,data[1].numpy()))\n",
    "\n",
    "\n",
    "for batch,data in enumerate(dataloaders['val']):\n",
    "    if batch==0:\n",
    "        X_test = torch.squeeze(resnet50(data[0])).numpy()\n",
    "        y_test = data[1].numpy()\n",
    "    else:\n",
    "        X_test = np.vstack((X_test,torch.squeeze(resnet50(data[0])).numpy()))\n",
    "        y_test = np.hstack((y_test,data[1].numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Train logistic regression classifier on the ResNet features</font>\n",
    "\n",
    "And then we'll evaluate its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear',random_state=0,max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: {}\\n\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Confusion matrix: \\n {}\".format(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use this same 2048-d representation to construct a k-nearest neighbor classifier. Give the test\n",
    "accuracies obtained for k = 1, 3, 5. Note: If you use sklearn.neighbors.KNeighborsClassifier,\n",
    "you might want to set algorithm=’kd tree’\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
