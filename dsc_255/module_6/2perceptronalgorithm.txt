(ethereal music) - Welcome back. So we will now look at the Perceptron algorithm, a simple and elegant method for learning a linear classifier that came out of the neuroscience literature and has been enormously influential in machine learning. So here's the basic setup, again, we have data points in three-dimensional space and each point has a label minus 1 or plus 1. For data like this, a linear classifier is given by w and b, where w is a three dimensional vector and b is a scaler offset. On any given point, what we do is to compute the linear function, w dot x plus b, and our prediction is the sign of that value. If w dot x plus b evaluates to something positive, we predict plus 1. If it evaluates to something negative, we predict minus one. Now, if the correct label is y either plus one or minus one, then we are correct, if y has the same sign as w dot x plus b, and as we saw last time, an equivalent way to write that is to say that we are correct if y times w dot x plus b is greater than 0. That is to say either y and w dot x plus b are both positive or they're both negative. Okay, so this is what linear classification looks like in three dimensional space. But how do we learn a linear classifier from data? What we are gonna do is to take an optimization approach to this, which means that the first thing we have to do is to write down a loss function. So what is a suitable loss function? Suppose we have a model, w and b, a linear classifier, w and b, how can we define the loss of that classifier on a specific point x,y? Well, there are lots of different ways to do this. Here's one. Okay, so here's one idea for a loss function. If we are correct on that point, if our model w,b is correct on the point x,y, that is to say if y times w dot x plus b is greater than 0, then we say that the loss is 0. Okay, loss equals 0, no penalty, we got it right. But if we are wrong, in other words, if y and w dot x plus b have opposite signs, then we do have to incur a loss and we say that the loss is this, so let's draw a little picture of this. So on the horizontal axis, I will put the value y times w dot x plus b. So ideally it would be greater than 0 and what we are saying is that if it is positive, in other words, if we get the point right, then our loss is 0. On the other hand, if it's negative, then our loss looks like this. So this is our loss function. So notice that the loss function is either 0 if we get it correct or at some positive number. So let's look at a little example. Let's say that the correct label is -1, and let's say that w dot x plus b is equal to 0.1. Now, if that's the case, it means that we would actually predict plus one, since w dot x plus b is a positive number, so we'd get it wrong and our loss would be 0.1. So we got it wrong, but our loss was relatively small because although we were wrong, we were not far off. Our value was actually pretty close to 0, was pretty close to the negative side. On the other hand, if w dot x plus b equals 10, then again we get it wrong, but this time our loss is much larger, our loss is 10. So anytime we make the wrong prediction, we incur a loss, and the amount of the loss was how far off we were, and that's why we get a loss function that looks like this. Okay, so that's our loss function. Now, let's go ahead and derive a stochastic gradient descent algorithm for minimizing this loss. Now, in stochastic gradient descent, the idea is to cycle through the dataset over and over, and to keep updating the parameters w and b along the way. Each update of w and b just depends on a single data point, and the amount of the update is given by the derivative of the loss function. So let's see what this works out to be. So let's say our current parameters are w,b. We're cycling through the data and now we have arrived at data point x,y. How should we update w,b based on this point? Well, if we get the point correct, if y times w dot x plus b is greater than 0, then our loss is 0 and so the derivative of the loss is 0 as well, and so we do not update w and b. But let's say we don't get the point correct. In this case, our loss is negative y times w dot x plus b, and what we need to compute is the derivative of the loss with respect to our parameters, with respect to w, and with respect to b. So let's see, if we compute the derivative of this with respect to w, we get negative yx, and if we compute the derivative with respect to b, we get negative y. So those are the derivatives, and what this means is that the stochastic gradient update looks like this. So we take our w and we send it, we move it in the opposite direction of the derivative, so we say plus yx, and then we also have a step size in there, which we'll call ada. So this is gonna be our step size, and similarly with b, we take b and we move it in the opposite direction of the derivative. So instead of doing minus y, we do plus y, and again, we have the step size ada. So very simple updates. We just take our w and b and add these small quantities to them. Now, what step size should we choose? To keep things simple, let's just set ada equal to 1... And this gives us an extremely simple algorithm. We just keep cycling through the data and anytime we make a mistake, we do these updates. This is the Perceptron algorithm. So let's go ahead and write it out nicely. This is what it looks like. So we start by initializing w and b to 0, so w is a three dimensional vector that's all 0s, and b is just the number 0, and now we keep going through the data, and when we are at data point x,y, if we get it correct, we do nothing. If we get it wrong, then we make these small updates, we make these little updates to w and b. We take w and we add yx to it, and we take b and we add y to it. That's it. Four lines of code. So let's see how this works. Here's a data set that consists of 85 data points. They're linearly separable which is to say it is possible to separate the two classes using a linear boundary. So let's see what the Perceptron does on this. So when we ran it, it took nine iterations, that is, it went through the dataset nine times, and by the end of the ninth iteration, it had found this boundary that perfectly separates the two classes, and at that point the algorithm converged, it was not making any more mistakes, and as a result, it would not update w and b any longer. So that's an important thing to keep in mind about the algorithm. Once it gets to a point where it's correctly classified the training set, it converges, it doesn't update w and b any longer, and so when we ran it, it took nine iterations, nine passes through the data set, it made a bunch of mistakes along the way, and after nine passes it converged at this linear boundary that no longer was making any mistakes on the training set. Now, when running the Perceptron algorithm, it is common to randomize the order of the data points. So to randomly permute the training set. Now, if you do that, then you could get a different outcome every time you run the Perceptron, and so let's see some examples of these different outcomes. So this first picture corresponds to some particular permutation of the training set. Then we did a different random permutation and the second time it took 15 iterations and arrived at this boundary. The third time we did another random permutation, and this time it took eight iterations through the data and it arrived at this boundary. The next time it did 14 iterations and arrived at this boundary. The next time it did eight iterations and arrived at this boundary. So a slightly different result each time. But the key thing to notice is that in every single instance, it found a boundary that perfectly separated the two classes, and it turns out that, in fact, it is guaranteed to do this. There's a mathematical convergence result that shows that as long as the training data is linearly separable, as long as there exists some linear boundary between the two classes, the Perceptron is guaranteed to find such a boundary. So this is a truly remarkable result. We have something that's just four lines of code, an extremely simple algorithm, and it is guaranteed to perfectly separate the two classes as long as a perfect separator exists. The Perceptron is truly a gem of machine learning. 