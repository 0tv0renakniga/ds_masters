{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='magenta'>Classifying wineries using nearest neighbor</font>\n",
    "\n",
    "#### Load the `wine` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('wine.data',delimiter=',')\n",
    "features = data[:,1:]\n",
    "labels = data[:,0].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also print out the labels of the points. Notice that they are 1,2,3, and that the points are not in random order!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure for 1-NN classifier with Euclidean distance\n",
    "\n",
    "The function `classifier` takes three inputs:\n",
    "* `x`, a query point\n",
    "* `features`, a training set of data points\n",
    "* `labels`, the labels of the training points\n",
    "\n",
    "It returns the label of the nearest neighbor of `x` in the training set.\n",
    "\n",
    "A word about the code: `x-features` looks strange because `x` is a vector while `features` is an entire data set. And what is the effect of `axis=1`? Things to look into..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x,features,labels):\n",
    "    dist = np.sqrt(np.sum((x-features)**2,axis=1))\n",
    "    return labels[np.argmin(dist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure for estimating confusion matrix using leave-one-out cross validation\n",
    "\n",
    "The procedure `leave_one_out` takes two inputs:\n",
    "* `features`, a training set of data points\n",
    "* `labels`, the labels of the training points\n",
    "\n",
    "It returns a confusion matrix for the 1-NN classifier based on this training set, estimated using leave-one-out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out(features,labels):\n",
    "    confusion = np.zeros((3,3))\n",
    "    for i in range(len(features)):\n",
    "        x = features[i]\n",
    "        y = labels[i]\n",
    "        # exclude x from features and labels\n",
    "        train_features = np.delete(features,i,axis=0)\n",
    "        train_labels = np.delete(labels,i)\n",
    "        yhat = classifier(x,train_features,train_labels)\n",
    "        confusion[y-1,yhat-1] += 1 # labels are 1,2,3 but matrix is zero-indexed\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure for estimating confusion matrix using k-fold cross validation\n",
    "\n",
    "The procedure `k_fold` takes the same inputs as `leave_one_out`, with an additional parameter:\n",
    "* `k`, the number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k,features,labels):\n",
    "    confusion = np.zeros((3,3))\n",
    "    n = features.shape[0]\n",
    "    for i in range(k):\n",
    "        test_ids = np.arange(i*n/k,(i+1)*n/k,dtype=int)\n",
    "        train_ids = np.setdiff1d(np.arange(n),test_ids)\n",
    "        for j in test_ids:\n",
    "            confusion[labels[j]-1,classifier(features[j],features[train_ids],labels[train_ids])-1] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate confusion matrix and accuracy using LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = leave_one_out(features,labels)\n",
    "accuracy = np.sum(np.diag(conf_mat))/np.sum(conf_mat)\n",
    "print(\"confusion matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate confusion matrix and accuracy using k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(2,100,5)\n",
    "accuracy = np.zeros(len(k))\n",
    "for i in range(len(k)):\n",
    "    accuracy[i] = np.sum(np.diag(k_fold(k[i],features,labels)))/np.sum(k_fold(k[i],features,labels))\n",
    "plt.plot(k,accuracy)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data\n",
    "\n",
    "The `wine` data has features with widely varying ranges. Will nearest neighbor classification performance improve if we normalize the data so that each feature takes on (roughly) the same range of values? Let's try two normalization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: (x-mean)/std\n",
    "\n",
    "First let's try normalizing each feature so that it has mean zero and variance one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features by subtracting the mean and dividing by the standard deviation\n",
    "def normalize1(features):\n",
    "    return (features - np.mean(features,axis=0))/np.std(features,axis=0)\n",
    "features_norm = normalize1(features)\n",
    "# rerun the cross validations\n",
    "conf_mat = leave_one_out(features_norm,labels)\n",
    "accuracy = np.sum(np.diag(conf_mat))/np.sum(conf_mat)\n",
    "print(\"Leave One Out Cross Validation\")\n",
    "print(\"confusion matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "print(\"k-fold Cross Validation\")\n",
    "k = np.arange(2,100,5)\n",
    "accuracy = np.zeros(len(k))\n",
    "for i in range(len(k)):\n",
    "    accuracy[i] = np.sum(np.diag(k_fold(k[i],features_norm,labels)))/np.sum(k_fold(k[i],features_norm,labels))\n",
    "plt.plot(k,accuracy)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Map x into [0,1]\n",
    "\n",
    "Another form of normalization is to linearly remap each feature so that it takes values in the range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features by projecting coordinates into [0,1]\n",
    "def normalize2(features):\n",
    "    return (features - np.min(features,axis=0))/(np.max(features,axis=0) - np.min(features,axis=0))\n",
    "features_norm = normalize2(features)\n",
    "# rerun the cross validations\n",
    "conf_mat = leave_one_out(features_norm,labels)\n",
    "accuracy = np.sum(np.diag(conf_mat))/np.sum(conf_mat)\n",
    "print(\"Leave One Out Cross Validation\")\n",
    "print(\"confusion matrix:\")\n",
    "print(conf_mat)\n",
    "print(\"accuracy: {:.2f}\".format(accuracy))\n",
    "\n",
    "print(\"k-fold Cross Validation\")\n",
    "k = np.arange(2,100,5)\n",
    "accuracy = np.zeros(len(k))\n",
    "for i in range(len(k)):\n",
    "    accuracy[i] = np.sum(np.diag(k_fold(k[i],features_norm,labels)))/np.sum(k_fold(k[i],features_norm,labels))\n",
    "plt.plot(k,accuracy)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: normalization does improve the classification accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d733caf4ffc39d0fbd9a2ba54ef4b7d515956d8048931f8241efe3827fb2d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
