(bright music) - Welcome back, everybody. Our next topic is one of the oldest and most widely used forms of classification, nearest neighbor. So, let's go back to our previous example. What we wanna do is to take an image of a handwritten digit and say what digit it is. As we mentioned, the machine learning approach to solving this problem is to assemble a large set of examples, a training set. Luckily, there's a very nice such collection called the MNIST data set. It is a training set of 60,000 images, each with their corresponding labels zero through nine. So, 60,000 images, 10 labels. There's roughly 6,000 images of each of the digits. So, we'll use these images to build a classifier. And then, there's a separate desk set of 10,000 additional images, which we'll use to evaluate the classifier. The nearest neighbor approach to classification is really pretty elementary. We have our training set, in this case, 60,000 images. Let's call them x1 through x60,000. So, our 60,000 training images. And for each of them, we have the corresponding label. Let's call them y1 through y60,000. When we get a new image x that we wanna classify, the way we do it is by looking at our 60,000 training images and finding the one that's closest to x. In this case, who knows, maybe it is this image over here. So, we find the image that's closest to x and we simply return the label of that training image. And in this case, we'd get it right. We'd say that it's a three. So, that's basically it. In order to fully specify this scheme, the one last thing that we need to finalize is the notion of distance between images. We wanna find the nearest neighbor. What exactly does that mean? In fact, we actually haven't talked about the way in which these images are represented. So, let's start with that first. Okay, so what's the data space? In the case of MNIST, each of these images is 28 by 28, so it's 28 pixels high and it's 28 pixels wide. And therefore, the total number of pixels in one of these images is 28 times 28, which is 784. Each individual pixel is just given by a single number in the range 0 to 255. 0 means that it's completely black like it is in that corner and 255 means that it's completely wide. So, in general, it'll be something in that range. So, this is what our images look like. In machine learning, it's customary to represent data in the form of vectors. And in this case, we can do that quite easily by taking an image and just stretching it out into a vector. So, how would we do that? Well, we can take the very first row of the image, those 28 numbers, and just copy them down over here. And then, we take the second row, the next 28 pixels and copy them down over here. And finally, we get the last row, the 28th row, and we copy it down at the end. So, instead of the square image, we get a single vector with 784 entries, a 784-dimensional vector. Because we are representing images in this way, we can say that our data space, script X is R to the 784. That is to say 784-dimensional euclidean space. That's the space in which the data lies. The labels lie in the space zero to nine. So, the labels lie in a very simple space. Okay. So, that's what the data looks like. We still have to talk about how we measure the distance between two images. That is to say the distance between two of these 784-dimensional vectors. One simple choice is to just use euclidean distance. So, euclidean distance for 784-dimensional vectors is a direct extension of our usual euclidean distance for two or three-dimensional vectors. So, let's just recall what that formula is. So, suppose we have these two points over here, x, whose coordinates are 1, 2, and z whose coordinates are 3, 5. What is the euclidean distance between x and z? Well, it is simply the length of the line connecting x with z. So, that's the euclidean distance. And the way we determine the length of the line is to look at the displacement along the first coordinate which is 2, and the displacement along the second coordinate, which is 3. And so, the length of the line by the Pythagorean formula is the square root of 2 squared plus 3 squared, which is the square root of 13. So, what we would say is that the distance between x and z, which we write like this, is the square root of 13. That's euclidean distance in two dimensions. And it's literally the physical distance between points x and z. In 784 dimensions, it's the same formula. So, now, let's say that x and z are 784-dimensional vectors. So, x looks something like this. It's this long vector with 784 entries. And z is also something of the same type, another long vector with 784 entries. The euclidean distance between them in order to compute it, we look at corresponding entries, subtract them, and then square these differences, add them up, and take the square root of the whole thing. And so, that's euclidean distance in 784 dimensions. And similarly, we can define euclidean distance in euclidean space of any dimension whatsoever. Great. So, now, we have a way of representing images and of computing the distance between them. And so, we can finally realize our nearest neighbor classifier. Okay. So, we have our 60,000 training images. When we get a new image x, which is a 784-dimensional vector, we compute its distance, it's euclidean distance to the first training image, and then to the second training image, and then all the way to the 60,000th training image. We compute all of these distances and we look for the smallest distance. That's the nearest neighbor. And once we found the nearest neighbor, we simply return the label of that neighbor. So, it's a nice simple method, but is it any good? How do we assess this? What is the accuracy of this classifier? So, let's look at some numbers. We have a training set of 60,000 points. What is the error rate on the actual training points? That's to say, suppose we take this classifier and we give it an image that's actually part of the training set. What would it do with it? Okay, so we give it an image that's in the training set. It computes the distance to all 60,000 images. It's gonna find an exact match. And therefore, it's guaranteed to get it correct. So, the error rate on the training points is actually zero. Does that mean this is an amazing classifier? No, not at all. But what it shows is the training error. That is to say the error rate on the training set is not a good measure of the quality of a classifier. In general, it's going to be overly optimistic. And this is the entire reason why we have a separate test set of 10,000 points. So, there was this test set that was also part of the MNIST data set. It's much smaller than the training set, but the key point is that we never looked at the test set while building the classifier. We kept it apart. And now that the classifier is ready, we can use this test set to evaluate the classifier to see how good it actually is. What sort of error rate should we be happy with or unhappy with? Well, one kind of baseline that we can compare against is the error rate of the dumbest possible classifier. A completely random classifier. A random classifier is one that doesn't even look at an image. It just closes its eyes and picks a number from zero to one at random. Sorry, from zero to nine at random. What is the error rate of such a classifier? Well, for any given image, the chance that it guesses its label correctly is exactly 1 in 10. And so, the error rate is 90%. We definitely wanna be able to do better than that. And indeed, it turns out that the error rate of nearest neighbor on this problem, the error rate on the test set is only 3.09%. It makes mistakes on about 3% of the examples. This is pretty impressive for such a simple classifier. And next time, we'll take a look at some of the kinds of mistakes that it makes and see whether it's possible to bring this error rate down even further. 