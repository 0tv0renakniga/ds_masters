{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: right;\">\n",
    "   Randall Rogers<br>\n",
    "   DSC 255: Machine Learning Fundamentals<br>\n",
    "   Homework 1: Nearest Neighbor Classification<br>\n",
    "   Spring 2025 <br>\n",
    "</div>\n",
    "\n",
    "#### Question 1\n",
    "*Casting an image into vector form. A $10 \\times 10$ greyscale image is mapped to a $d$-dimensional vector, with one pixel per coordinate. What is $d$?*\n",
    "\n",
    "**Solution** \n",
    "\n",
    "---\n",
    "\n",
    "Given: $l = 10$ ; $w = 10$ ; $d = l \\times w$\n",
    "\n",
    "Now, calculate the number of dimensions $d$.\n",
    "\n",
    "$d = l \\times w$\n",
    "\n",
    "$d = 10 \\times 10$\n",
    "\n",
    "$d = 100$\n",
    "   \n",
    "$\\therefore$ a $10 \\times 10$ greyscale image is mapped to a $100$-dimensional vector\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 2\n",
    "\n",
    "*The length of a vector. The Euclidean (or $L_2$) length of a vector $x \\in \\mathbb{R}^d$ is*\n",
    "\n",
    "$$\n",
    "\\|x\\| = \\sqrt{\\sum_{i=1}^{d} x_i^2}\n",
    "$$\n",
    "\n",
    "*where $x_i$ is the $i$-th coordinate of $x$. This is the same as the Euclidean distance between $x$ and the origin. What is the length of the vector which has a 1 in every coordinate? Your answer may be a function of $d$.*\n",
    "\n",
    "**Solution** \n",
    "\n",
    "---\n",
    "\n",
    "We are given the following:\n",
    "   \n",
    "$$\\exists x \\in \\mathbb{R}^d : x_i = 1 \\ \\forall i \\in \\mathbb{N}^d$$\n",
    "\n",
    "It follows that,\n",
    "\n",
    "$\\|x\\| = \\sqrt{\\sum_{i=1}^{d} x_i^2}$ $\\rightarrow$ *Definiton of $L_2$*\n",
    "\n",
    "$\\|x\\| = \\sqrt{\\left(x_1^{2}+x_2^{2}+...+x_d^{2}\\right)}$ $\\rightarrow$ *Expand summation*\n",
    "\n",
    "$\\|x\\| = \\sqrt{\\left(1^{2}+1^{2}+...+1^{2}\\right)}$ $\\rightarrow$ $x_i = 1 \\ \\forall i \\in \\mathbb{N}^d$  \n",
    "\n",
    "$\\|x\\| = \\sqrt{\\left(1+1+...+1\\right)}$ $\\rightarrow$ $1^2 = 1$  \n",
    "\n",
    "$\\|x\\| = \\sqrt{d}$ $\\rightarrow$ $\\left(1+1+...+1\\right) = d$ , *Since there are d ones*\n",
    "\n",
    "$\\therefore$ the length of the vector which has a 1 in every coordinate is $\\|x\\| = \\sqrt{d}$\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 3\n",
    "\n",
    "*Euclidean distance. What is the Euclidean distance between the following two points in $\\mathbb{R}^3$?*\n",
    "\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 \\\\\n",
    "   2 \\\\\n",
    "   3\n",
    "   \\end{bmatrix},\n",
    "   \\begin{bmatrix}\n",
    "   3 \\\\\n",
    "   2 \\\\\n",
    "   1\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "   **Solution** \n",
    "\n",
    "---\n",
    "\n",
    "   Let, $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ , $y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "   It follows that,\n",
    "   $x_1 = 1$ , $x_2 = 2$ , $x_3 = 3$ , $y_1 = 3$ , $y_2 = 2$ , $y_3 = 1$\n",
    "\n",
    "   The Euclidean distance in an n-dimensional space is defined as the following:\n",
    "\n",
    "   $$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$\n",
    "\n",
    "   x and y are 3-dimensional vectors. Hence, $n=3$ and the equation above becomes:\n",
    "\n",
    "   $$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{3} (x_i - y_i)^2}$$\n",
    "\n",
    "   After, expanding the summation and substituting $x_1$... $y_3$ the Euclidean distance formula for a 3-dimensional space is:\n",
    "\n",
    "   $\\|x-y\\| = \\sqrt{\\left((1 - 3)^2+(2 - 2)^2+(3 - 1)^2\\right)}$\n",
    "   \n",
    "   $\\|x-y\\| = \\sqrt{\\left(4+0+4\\right)}$\n",
    "   \n",
    "   $\\|x-y\\| = \\sqrt{\\left((1 - 3)^2+(2 - 2)^2(3 - 1)^2\\right)}$\n",
    "\n",
    "   Hence, $\\|x-y\\| = \\sqrt{8}$\n",
    "\n",
    "   $\\therefore$ the Euclidean distance between $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ , $y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$ in $\\mathbb{R}^3$ is $\\|x-y\\| = \\sqrt{8}$\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 4\n",
    "\n",
    "*Accuracy of a random classifier.* A particular data set has 4 possible labels, with the following frequencies:*\n",
    "   \n",
    "<center>\n",
    "\n",
    "| Label | Frequency |\n",
    "| :---: | :-------: |\n",
    "| $A$   | $50\\%$    |\n",
    "| $B$   | $20\\%$    |\n",
    "| $C$   | $20\\%$    |\n",
    "| $D$   | $10\\%$    | \n",
    "\n",
    "</center>\n",
    " \n",
    "(a) What is the error rate of a classifier that picks a label $(A, B, C, D)$ at random, each with probability $\\frac{1}{4}$?\n",
    "\n",
    "(b) One very simple type of classifier just returns the same label, always.\n",
    "   - What label should it return?\n",
    "   - What will its error rate be?\n",
    "\n",
    "**Solution (a)** \n",
    "\n",
    "---\n",
    "\n",
    "The Probability of event E is defined as:\n",
    "\n",
    "$$P(E_i) = f_i \\times p_i$$\n",
    "\n",
    "   - $f_i$ is the frequency of each event $E_i$ $\\forall i \\in \\mathbb{N}$\n",
    "   - $p_i$ is the probability of each event $E_i$ $\\forall i \\in \\mathbb{N}$\n",
    "   \n",
    "The Probability of selecting event E or event F is defined as:\n",
    "\n",
    "$$P(E,F) = P(E)+P(F)$$\n",
    "\n",
    "First, solve for $P(A)$ , $P(B)$ , $P(C)$ , $P(D)$.\n",
    "\n",
    "Let $p_a = p_b = p_c = p_d = \\frac{1}{4} = 0.25$ and $f_a = 0.5$ , $f_b = 0.2$ , $f_c= 0.2$ , $f_d = 0.1$  \n",
    "\n",
    "$$P(A) = f_a \\times p_a = 0.5 \\times 0.25 = 0.125$$\n",
    "\n",
    "$$P(B) = f_b \\times p_b = 0.2 \\times 0.25 = 0.050$$\n",
    "\n",
    "$$P(C) = f_c \\times p_c = 0.2 \\times 0.25 = 0.050$$\n",
    "\n",
    "$$P(D) = f_d \\times p_d = 0.1 \\times 0.25 = 0.025$$\n",
    "\n",
    "Hence, $P(A)=0.125$ , $P(B)=0.05$ , $P(C)=0.05$ , $P(D)=0.025$\n",
    "\n",
    "Now, solve for $P(A,B,C,D)$\n",
    "\n",
    "$$P(A,B,C,D) = P(A) + P(B) + P(C) + P(D) = 0.125+0.05+0.050.025 = 0.25$$\n",
    "\n",
    "Hence, $P(A,B,C,D)$ or accuracy is $0.25$\n",
    "\n",
    "The error rate($ER$) is defined as: $ER = 1 - accuracy$\n",
    "\n",
    "Lastly, solve for the error rate.\n",
    "\n",
    "$$ER = 1 - accuracy = 1 - 0.25 = 0.75$$\n",
    "\n",
    "$\\therefore$ the error rate of a classifier that picks a label $(A, B, C, D)$ at random, each with probability $\\frac{1}{4}$ is $75$%.\n",
    "\n",
    "---\n",
    "\n",
    "**Solution (b)** \n",
    "\n",
    "---\n",
    "\n",
    "*What label should it return?*\n",
    "\n",
    "Given a very simple classifier ($AVSC$), such that it always returns the same label. The classifier should return the label with the highest frequency.\n",
    "\n",
    "$\\therefore$ $AVSC$ should return label $A$.\n",
    "\n",
    "*What will its error rate be?*\n",
    "\n",
    "Label $A$ makes up %$50$ percent of the population. The proportion of correct predictions is $50$% or $0.50$.\n",
    "\n",
    "Solving for error rate ($ER$) using the equation in *part (a)*, we have the following:\n",
    "\n",
    "$$ER = 1 - accuracy = 1 - 0.50 = 0.50$$\n",
    "\n",
    "$\\therefore$ $AVSC$ that returns label $A$ every time will have an error rate of $0.50$ or $50$%.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 5\n",
    "\n",
    "*In the picture below, there are nine training points, each with label either square or star. These will be used to guess the label of a query point at $(3.5, 4.5)$, indicated by a circle. Suppose Euclidean distance is used.*\n",
    "\n",
    "<center>\n",
    "\n",
    "![Training Points](dsc_255_hw1_5.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "(a) *How will the point be classified by 1-NN? The options are square, star, or ambiguous.*\n",
    "\n",
    "(b) *By 3-NN?*\n",
    "\n",
    "(c) *By 5-NN?*\n",
    "\n",
    "\n",
    "**Solution (a)**\n",
    "\n",
    "---\n",
    "\n",
    "We know the point $p$ is located at $(3.5,4.5)$ and from the picture we are given the following:\n",
    "\n",
    "$$\\begin{bmatrix}\\star_{(2,6)} & \\blacksquare_{(4,6)} & \\star_{(6,6)} \\\\ \\blacksquare_{(2,4)} & \\star_{(4,4)} & \\blacksquare_{(6,4)} \\\\ \\star_{(2,2)} & \\blacksquare_{(4,2)} & \\blacksquare_{(6,2)}\\end{bmatrix}$$\n",
    "\n",
    "The distance equation is given below:\n",
    "\n",
    "$$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$\n",
    "\n",
    "Now solve for the distance each element is away from point $p$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\|p - \\star_{(2,6)}\\| &= \\sqrt{\\left((3.5 - 2)^2 + (4.5 - 6)^2\\right)} = \\sqrt{\\left((1.5)^2 + (-1.5)^2\\right)} &\\approx 2.12 \\\\\n",
    "\\|p - \\blacksquare_{(4,6)}\\| &= \\sqrt{\\left((3.5 - 4)^2 + (4.5 - 6)^2\\right)} = \\sqrt{\\left((-0.5)^2 + (-1.5)^2\\right)} &\\approx 1.58 \\\\\n",
    "\\|p - \\star_{(6,6)}\\| &= \\sqrt{\\left((3.5 - 6)^2 + (4.5 - 6)^2\\right)} = \\sqrt{\\left((-2.5)^2 + (-1.5)^2\\right)} &\\approx 2.92 \\\\\n",
    "\\|p - \\blacksquare_{(2,4)}\\| &= \\sqrt{\\left((3.5 - 2)^2 + (4.5 - 4)^2\\right)} = \\sqrt{\\left((1.5)^2 + (0.5)^2\\right)} &\\approx 1.58 \\\\\n",
    "\\|p - \\star_{(4,4)}\\| &= \\sqrt{\\left((3.5 - 4)^2 + (4.5 - 4)^2\\right)} = \\sqrt{\\left((-0.5)^2 + (0.5)^2\\right)} &\\approx 0.71 \\\\\n",
    "\\|p - \\blacksquare_{(6,4)}\\| &= \\sqrt{\\left((3.5 - 6)^2 + (4.5 - 4)^2\\right)} = \\sqrt{\\left((2.5)^2 + (0.5)^2\\right)} &\\approx 2.55 \\\\\n",
    "\\|p - \\star_{(2,2)}\\| &= \\sqrt{\\left((3.5 - 2)^2 + (4.5 - 2)^2\\right)} = \\sqrt{\\left((1.5)^2 + (2.5)^2\\right)} &\\approx 2.92 \\\\\n",
    "\\|p - \\blacksquare_{(4,2)}\\| &= \\sqrt{\\left((3.5 - 4)^2 + (4.5 - 2)^2\\right)} = \\sqrt{\\left((-0.5)^2 + (2.5)^2\\right)} &\\approx 2.55 \\\\\n",
    "\\|p - \\blacksquare_{(6,2)}\\| &= \\sqrt{\\left((3.5 - 6)^2 + (4.5 - 2)^2\\right)} = \\sqrt{\\left((2.5)^2 + (2.5)^2\\right)} &\\approx 3.54\n",
    "\\end{align*}\n",
    "$$\n",
    "   \n",
    "The distance results are below in *Table 1*.\n",
    "   \n",
    "<center>\n",
    "\n",
    "| Element | Distance to $p$| Distance Rank |\n",
    "| :-------------: | :------------: | :-----------: |\n",
    "| $\\star_{(4,4)}$ | $0.71$    | $1^{st}$ |\n",
    "| $\\blacksquare_{(2,4)}$ | $1.58$    | $T2^{nd}$ |\n",
    "| $\\blacksquare_{(4,6)}$ | $1.58$    | $T2^{nd}$ |\n",
    "| $\\star_{(2,6)}$ | $2.12$    | $4^{th}$ |\n",
    "| $\\blacksquare_{(4,2)}$ | $2.55$    | $T5^{th}$ |\n",
    "| $\\blacksquare_{(6,4)}$ | $2.55$    | $T5^{th}$ |\n",
    "| $\\star_{(2,2)}$ | $2.92$    | $T7^{th}$ |\n",
    "| $\\star_{(6,6)}$ | $2.92$    | $T7^{th}$ |\n",
    "| $\\blacksquare_{(6,2)}$ | $3.54$    | $9^{th}$ |\n",
    "\n",
    "</center>\n",
    "\n",
    "*Table 1: ranking element distance to point p, closest to farthest*\n",
    "\n",
    "      \n",
    "From *Table 1* $\\star_{(4,4)}$ is closest to point $p$.\n",
    "\n",
    "$\\therefore$ the point $p$ will be classified as a star ($\\star$) by 1-NN.\n",
    "\n",
    "---   \n",
    "\n",
    "**Solution (b)** \n",
    "\n",
    "---\n",
    "\n",
    "From *Table 1* in *Solution (a)* The three closest elements to point $p$ are $\\star_{(4,4)}$ ,$\\blacksquare_{(2,4)}$ , and $\\blacksquare_{(4,6)}$. The frequency counts are as follows: $\\blacksquare : 2$ and $\\star : 1$.\n",
    "\n",
    "$\\therefore$ the point $p$ will be classified as a square ($\\blacksquare$) by 3-NN.\n",
    "\n",
    "---\n",
    "\n",
    "**Solution (c)** \n",
    "\n",
    "---\n",
    "\n",
    "Again from *Table 1* in *Solution (a)* The five closest elements to point $p$ are $\\star_{(4,4)}$ ,$\\blacksquare_{(2,4)}$ , $\\blacksquare_{(4,6)}$, $\\star_{(2,6)}$ , and $\\blacksquare_{(4,2)}$ or $\\blacksquare_{(6,4)}$ . The frequency counts are as follows: $\\blacksquare : 3$ and $\\star : 2$.\n",
    "\n",
    "$\\therefore$ the point $p$ will be classified as a square ($\\blacksquare$) by 5-NN.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 6\n",
    "*We decide to use 4-fold cross-validation to figure out the right value of $k$ to choose when running $k$-nearest neighbor on a data set of size 10,000. When checking a particular value of $k$, we look at four different training sets. What is the size of each of these training sets?*\n",
    "\n",
    "**Solution** \n",
    "\n",
    "---\n",
    "\n",
    "Let, $k=4$ and $n=10000$\n",
    "\n",
    "Calculate the size of each fold ($f_s$).\n",
    "\n",
    "$f_s = \\frac{n}{k} = \\frac{10000}{4} = 2500$\n",
    "\n",
    "Hence, the size of each fold is $2500$\n",
    "\n",
    "Now, we will solve for the size of each training set ($t_s$) using the equation below:\n",
    "\n",
    "$$t_s = (k-1)\\times f_s$$\n",
    "\n",
    "Calculate the size of each training set such that $f_s=2500$ and $k=4$.\n",
    "\n",
    "$t_s = (k-1)\\times f_s = (4-1) \\times 2500 = 7500$\n",
    "\n",
    "$\\therefore$ the size of each training set is $7500$\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "#### Question 7\n",
    "\n",
    "*An extremal type of cross-validation is $n$-fold cross-validation on a training set of size $n$. If we want to estimate the error of $k$-NN, this amounts to classifying each training point by running $k$-NN on the remaining $n-1$ points, and then looking at the fraction of mistakes made. It is commonly called leave-one-out cross-validation (LOOCV).*\n",
    "\n",
    "*Consider the following simple data set of just four points:*\n",
    "\n",
    "<center>\n",
    "\n",
    "   ![Simple Data Set](dsc_255_hw1_7.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "*What is the LOOCV error for 1-NN? For 3-NN?*\n",
    "\n",
    "**Solution**\n",
    "\n",
    "---\n",
    "\n",
    "Let the points seen above be defined as the following:\n",
    "\n",
    "$$p_1 = +$$\n",
    "$$p_2 = +$$\n",
    "$$p_3 = -$$\n",
    "$$p_4 = +$$\n",
    "\n",
    "*for 1-NN*\n",
    "\n",
    "Each $p_i$ for 1-NN would be classified as follows\n",
    "\n",
    "<center>\n",
    "\n",
    "| Point | Nearest Neighbor| Classification | Prediction |\n",
    "| :-------------: | :------------: | :-----------: |:-----------: |\n",
    "| $p_1(+)$ | $p_2(+)$    | $+$ | $True$ |\n",
    "| $p_2(+)$ | $p_1(+)$    | $+$ | $True$ |\n",
    "| $p_3(-)$ | $p_4(+)$    | $+$ | $False$ |\n",
    "| $p_4(+)$ | $p_3(-)$    | $-$ | $False$ |\n",
    "\n",
    "</center>\n",
    "\n",
    "From the table above we have two correct predictions for the four points or an accuracy of $50$%.\n",
    "\n",
    "Now , calculate LOOCV error ($LOOCV_{error}$)\n",
    "\n",
    "$LOOCV_{error} = 1 - accuracy = 1 - 0.50 = 0.50$\n",
    "\n",
    "$\\therefore$ LOOCV error for 1-NN is $50$%.\n",
    "\n",
    "---\n",
    "\n",
    "*for 3-NN*\n",
    "\n",
    "Each $p_i$ for 3-NN would be classified as follows\n",
    "\n",
    "<center>\n",
    "\n",
    "| Point | Nearest Neighbors | Majority | Classification | Prediction | \n",
    "| :-------------: | :------------: | :-----------: | :-----------: | :-----------: |\n",
    "| $p_1(+)$ | $p_2(+)$ , $p_3(-)$ , $p_4(+)$ | $+$ | $+$ | $True$ |\n",
    "| $p_2(+)$ | $p_1(+)$ , $p_3(-)$ , $p_4(+)$ | $+$ | $+$ | $True$ |\n",
    "| $p_3(-)$ | $p_1(+)$ , $p_2(+)$ , $p_4(+)$ | $+$ | $+$ | $False$ |\n",
    "| $p_4(+)$ | $p_1(+)$ , $p_2(+)$ , $p_3(-)$ | $+$ | $+$ | $True$ |\n",
    "\n",
    "</center>\n",
    "\n",
    "From the table above we have three correct predictions for the four points\n",
    "\n",
    "Now , calculate LOOCV error ($LOOCV_{error}$)\n",
    "\n",
    "$LOOCV_{error} = 1 - accuracy = 1 - 0.75 = 0.25$\n",
    "\n",
    "$\\therefore$ LOOCV error for 3-NN is $25$%.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Programming Exercises\n",
    "\n",
    "Before attempting this problem, make sure that Python 3 and Jupyter are installed on your computer.\n",
    "\n",
    "8. **Nearest neighbor on MNIST.** For this problem, download the archive `hw1.zip`, available from the course website, and open it. The Jupyter notebook `nn-mnist.ipynb` implements a basic 1-NN classifier for a subset of the MNIST data set. It uses a separate training and test set. Begin by going through this notebook, running each segment and taking care to understand exactly what each line is doing.\n",
    "\n",
    "   Now do the following:\n",
    "   (a) For test point 100, print its image as well as the image of its nearest neighbor in the training set. Put these images in your writeup. Is this test point classified correctly?\n",
    "   (b) The confusion matrix for the classifier is a $10 \\times 10$ matrix $N_{ij}$ with $0 \\leq i, j \\leq 9$, where $N_{ij}$ is the number of test points whose true label is $i$ but which are classified as $j$. Thus, if all test points are correctly classified, the off-diagonal entries of the matrix will be zero.\n",
    "\n",
    "   - Compute the matrix $N$ for the 1-NN classifier and print it out.\n",
    "   - Which digit is misclassified most often? Least often?\n",
    "\n",
    "   (c) For each digit $0 \\leq i \\leq 9$: look at all training instances of image $i$, and compute their mean. This average is a 784-dimensional vector. Use the `show_digit` routine to print out these 10 average-digits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 255: Machine Learning\n",
    "\n",
    "## Homework 1\n",
    "\n",
    "### Nearest Neighbor Classification\n",
    "\n",
    "1. *Casting an image into vector form.* A $10 \\times 10$ greyscale image is mapped to a $d$-dimensional vector, with one pixel per coordinate. What is $d$?\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   Given: $l = 10$ ; $w = 10$ ; $d = l \\times w$\n",
    "\n",
    "   *Apply $d = l \\times w$ and substitute $l$ and $w$*\n",
    "\n",
    "      $d = l \\times w$\n",
    "\n",
    "      $d = 10 \\times 10$\n",
    "\n",
    "      $d = 100$\n",
    "   \n",
    "   $\\therefore$ the $10 \\times 10$ greyscale image is mapped to a $100$-dimensional vector\n",
    "\n",
    "2. *The length of a vector.* The Euclidean (or $L_2$) length of a vector $x \\in \\mathbb{R}^d$ is\n",
    "\n",
    "   $$\n",
    "   \\|x\\| = \\sqrt{\\sum_{i=1}^{d} x_i^2}\n",
    "   $$\n",
    "\n",
    "   where $x_i$ is the $i$-th coordinate of $x$. This is the same as the Euclidean distance between $x$ and the origin. What is the length of the vector which has a 1 in every coordinate? Your answer may be a function of $d$.\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   Given: $\\exists x \\in \\mathbb{R}^d : x_i = 1 \\ \\forall i \\in \\mathbb{N}^d$\n",
    "\n",
    "   It follows that,\n",
    "\n",
    "   $\\|x\\| = \\sqrt{\\sum_{i=1}^{d} x_i^2}$ $\\rightarrow$ *Definiton of $L_2$*\n",
    "\n",
    "   $\\|x\\| = \\sqrt{\\left(x_1^{2}+x_2^{2}+...+x_d^{2}\\right)}$ $\\rightarrow$ *Expand summation*\n",
    "\n",
    "   $\\|x\\| = \\sqrt{\\left(1^{2}+1^{2}+...+1^{2}\\right)}$ $\\rightarrow$ $x_i = 1 \\ \\forall i \\in \\mathbb{N}^d$  \n",
    "\n",
    "   $\\|x\\| = \\sqrt{\\left(1+1+...+1\\right)}$ $\\rightarrow$ $1^2 = 1$  \n",
    "\n",
    "   $\\|x\\| = \\sqrt{d}$ $\\rightarrow$ $\\left(1+1+...+1\\right) = d$ , *Since there are d ones*\n",
    "\n",
    "   $\\therefore$ the length of the vector which has a 1 in every coordinate is $\\|x\\| = \\sqrt{d}$\n",
    "\n",
    "3. *Euclidean distance.* What is the Euclidean distance between the following two points in $\\mathbb{R}^3$?\n",
    "\n",
    "   $$\n",
    "   \\begin{bmatrix}\n",
    "   1 \\\\\n",
    "   2 \\\\\n",
    "   3\n",
    "   \\end{bmatrix},\n",
    "   \\begin{bmatrix}\n",
    "   3 \\\\\n",
    "   2 \\\\\n",
    "   1\n",
    "   \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   Let, $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ , $y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "   It follows that,\n",
    "   $x_1 = 1$ , $x_2 = 2$ , $x_3 = 3$ , $y_1 = 3$ , $y_2 = 2$ , $y_3 = 1$\n",
    "\n",
    "   The Euclidean distance in an n-dimensional space is defined as the following:\n",
    "\n",
    "   $$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$\n",
    "\n",
    "   x and y are 3-dimensional vectors. Hence, $n=3$ and the equation above becomes:\n",
    "\n",
    "   $$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{3} (x_i - y_i)^2}$$\n",
    "\n",
    "   After, expanding the summation and substituting $x_1$... $y_3$ the Euclidean distance formula for a 3-dimensional space is:\n",
    "\n",
    "   $\\|x-y\\| = \\sqrt{\\left((1 - 3)^2+(2 - 2)^2+(3 - 1)^2\\right)}$\n",
    "   \n",
    "   $\\|x-y\\| = \\sqrt{\\left(4+0+4\\right)}$\n",
    "   \n",
    "   $\\|x-y\\| = \\sqrt{\\left((1 - 3)^2+(2 - 2)^2(3 - 1)^2\\right)}$\n",
    "\n",
    "   Hence, $\\|x-y\\| = \\sqrt{8}$\n",
    "\n",
    "   $\\therefore$ the Euclidean distance between $x = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ , $y = \\begin{bmatrix} 3 \\\\ 2 \\\\ 1 \\end{bmatrix}$ in $\\mathbb{R}^3$ is $\\|x-y\\| = \\sqrt{8}$\n",
    "\n",
    "4. *Accuracy of a random classifier.* A particular data set has 4 possible labels, with the following frequencies:\n",
    "   \n",
    "   <center>\n",
    "\n",
    "   | Label | Frequency |\n",
    "   | :---: | :-------: |\n",
    "   | $A$   | $50\\%$    |\n",
    "   | $B$   | $20\\%$    |\n",
    "   | $C$   | $20\\%$    |\n",
    "   | $D$   | $10\\%$    | \n",
    "\n",
    "   </center>\n",
    " \n",
    "   (a) What is the error rate of a classifier that picks a label $(A, B, C, D)$ at random, each with probability $\\frac{1}{4}$?\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   The Probability of event E is defined as:\n",
    "\n",
    "   $$P(E_i) = f_i \\times p_i$$\n",
    "      - $f_i$ is the frequency of each event $E_i$ $\\forall i \\in \\mathbb{N}$\n",
    "      - $p_i$ is the probability of each event $E_i$ $\\forall i \\in \\mathbb{N}$\n",
    "   \n",
    "   The Probability of selecting event E or event F is defined as:\n",
    "   $$P(E,F) = P(E)+P(F)$$\n",
    "\n",
    "   First, solve for $P(A)$ , $P(B)$ , $P(C)$ , $P(D)$.\n",
    "\n",
    "   Given: $p_a = p_b = p_c = p_d = \\frac{1}{4} = 0.25$ and $f_a = 0.5$ , $f_b = 0.2$ , $f_c= 0.2$ , $f_d = 0.1$  \n",
    "\n",
    "   $$P(A) = f_a \\times p_a = 0.5 \\times 0.25 = 0.125$$\n",
    "\n",
    "   $$P(B) = f_b \\times p_b = 0.2 \\times 0.25 = 0.050$$\n",
    "\n",
    "   $$P(C) = f_c \\times p_c = 0.2 \\times 0.25 = 0.050$$\n",
    "\n",
    "   $$P(D) = f_d \\times p_d = 0.1 \\times 0.25 = 0.025$$\n",
    "\n",
    "   Hence, $P(A)=0.125$ , $P(B)=0.05$ , $P(C)=0.05$ , $P(D)=0.025$\n",
    "\n",
    "   Now, solve for $P(A,B,C,D)$\n",
    "\n",
    "   $$P(A,B,C,D) = P(A) + P(B) + P(C) + P(D) = 0.125+0.05+0.050.025 = 0.25$$\n",
    "\n",
    "   Hence, $P(A,B,C,D)$ or accuracy is $0.25$\n",
    "\n",
    "   The error rate($ER$) is defined as: $ER = 1 - accuracy$\n",
    "\n",
    "   Lastly, solve for the error rate.\n",
    "\n",
    "   $$ER = 1 - accuracy = 1 - 0.25 = 0.75$$\n",
    "\n",
    "   $\\therefore$ the error rate of a classifier that picks a label $(A, B, C, D)$ at random, each with probability $\\frac{1}{4}$ is $75$%.\n",
    "\n",
    "   (b) One very simple type of classifier just returns the same label, always.\n",
    "   - What label should it return?\n",
    "\n",
    "      **Solution:**\n",
    "      Given a very simple classifier ($AVSC$), such that it always returns the same label. The classifier should return the label with the highest frequency.\n",
    "\n",
    "      $\\therefore$ $AVSC$ should return label $A$.\n",
    "\n",
    "   - What will its error rate be?\n",
    "\n",
    "      **Solution:** \n",
    "      Label $A$ makes up %$50$ percent of the population. The proportion of correct predictions is $50$% or $0.50$.\n",
    "\n",
    "      Solving for error rate ($ER$) using the equation in *part (a)*, we have the following:\n",
    "\n",
    "      $$ER = 1 - accuracy = 1 - 0.50 = 0.50$$\n",
    "\n",
    "      $\\therefore$ $AVSC$ that returns label $A$ every time will have an error rate of $0.50$ or $50$%.\n",
    "\n",
    "5. In the picture below, there are nine training points, each with label either square or star. These will be used to guess the label of a query point at $(3.5, 4.5)$, indicated by a circle.\n",
    "\n",
    "<center>\n",
    "\n",
    "![Training Points](dsc_255_hw1_5.png )\n",
    "\n",
    "</center>\n",
    "\n",
    "   Suppose Euclidean distance is used.\n",
    "   \n",
    "   **Background:** \n",
    "\n",
    "   We know the point $p$ is located at $(3.5,4.5)$ and from the picture we are given the following:\n",
    "\n",
    "   $$\\begin{bmatrix}\\star_{(2,6)} & \\blacksquare_{(4,6)} & \\star_{(6,6)} \\\\ \\blacksquare_{(2,4)} & \\star_{(4,4)} & \\blacksquare_{(6,4)} \\\\ \\star_{(2,2)} & \\blacksquare_{(4,2)} & \\blacksquare_{(6,2)}\\end{bmatrix}$$\n",
    "\n",
    "   The distance equation is given below:\n",
    "\n",
    "   $$\\|x-y\\| = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$$\n",
    "\n",
    "   Now solve for the distance each element is away from point $p$\n",
    "\n",
    "   $\\|p - \\star_{(2,6)}\\|= \\sqrt{\\left((3.5 - 2)^2+(4.5- 6)^2\\right)} = \\sqrt{\\left((1.5)^2+(-1.5)^2\\right)} \\approx 2.12$\n",
    "\n",
    "   $\\|p - \\blacksquare_{(4,6)}\\|= \\sqrt{\\left((3.5 - 4)^2+(4.5- 6)^2\\right)} = \\sqrt{\\left((-0.5)^2+(-1.5)^2\\right)} \\approx 1.58$\n",
    "\n",
    "   $\\|p - \\star_{(6,6)}\\|= \\sqrt{\\left((3.5 - 6)^2+(4.5- 6)^2\\right)} = \\sqrt{\\left((-2.5)^2+(-1.5)^2\\right)} \\approx 2.92$\n",
    "\n",
    "   $\\|p - \\blacksquare_{(2,4)}\\|= \\sqrt{\\left((3.5 - 2)^2+(4.5- 4)^2\\right)} = \\sqrt{\\left((1.5)^2+(0.5)^2\\right)} \\approx 1.58$\n",
    "\n",
    "   $\\|p - \\star_{(4,4)}\\|= \\sqrt{\\left((3.5 - 4)^2+(4.5- 4)^2\\right)} = \\sqrt{\\left((-0.5)^2+(0.5)^2\\right)} \\approx 0.71$\n",
    "\n",
    "   $\\|p - \\blacksquare_{(6,4)}\\|= \\sqrt{\\left((3.5 - 6)^2+(4.5- 4)^2\\right)} = \\sqrt{\\left((2.5)^2+(0.5)^2\\right)} \\approx 2.55$\n",
    "\n",
    "   $\\|p - \\star_{(2,2)}\\|= \\sqrt{\\left((3.5 - 2)^2+(4.5- 2)^2\\right)} = \\sqrt{\\left((1.5)^2+(2.5)^2\\right)} \\approx 2.92$\n",
    "\n",
    "   $\\|p - \\blacksquare_{(4,2)}\\|= \\sqrt{\\left((3.5 - 4)^2+(4.5- 2)^2\\right)} = \\sqrt{\\left((-0.5)^2+(2.5)^2\\right)} \\approx 2.55$\n",
    "\n",
    "   $\\|p - \\blacksquare_{(6,2)}\\|= \\sqrt{\\left((3.5 - 6)^2+(4.5- 2)^2\\right)} = \\sqrt{\\left((2.5)^2+(2.5)^2\\right)} \\approx 3.54$\n",
    "   \n",
    "   The distance results are below in $Table 1$\n",
    "   \n",
    "   <center>\n",
    "\n",
    "   | Element | Distance to $p$| Distance Rank |\n",
    "   | :-------------: | :------------: | :-----------: |\n",
    "   | $\\star_{(4,4)}$ | $0.71$    | $1^{st}$ |\n",
    "   | $\\blacksquare_{(2,4)}$ | $1.58$    | $T2^{nd}$ |\n",
    "   | $\\blacksquare_{(4,6)}$ | $1.58$    | $T2^{nd}$ |\n",
    "   | $\\star_{(2,6)}$ | $2.12$    | $4^{th}$ |\n",
    "   | $\\blacksquare_{(4,2)}$ | $2.55$    | $T5^{th}$ |\n",
    "   | $\\blacksquare_{(6,4)}$ | $2.55$    | $T5^{th}$ |\n",
    "   | $\\star_{(2,2)}$ | $2.92$    | $T7^{th}$ |\n",
    "   | $\\star_{(6,6)}$ | $2.92$    | $T7^{th}$ |\n",
    "   | $\\blacksquare_{(6,2)}$ | $3.54$    | $9^{th}$ |\n",
    "\n",
    "   </center>\n",
    "\n",
    "   (a) How will the point be classified by 1-NN? The options are square, star, or ambiguous.\n",
    "\n",
    "   **Solution:** \n",
    "      \n",
    "   From $Table 1$ $\\star_{(4,4)}$ is closest to point $p$.\n",
    "\n",
    "   $\\therefore$ the point $p$ will be classified as a star ($\\star$) by 1-NN.\n",
    "\n",
    "   (b) By 3-NN?\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   From $Table 1$ The three closest elements to point $p$ are $\\star_{(4,4)}$ ,$\\blacksquare_{(2,4)}$ , and $\\blacksquare_{(4,6)}$. The frequency counts are as follows: $\\blacksquare : 2$ and $\\star : 1$.\n",
    "\n",
    "   $\\therefore$ the point $p$ will be classified as a square ($\\blacksquare$) by 3-NN.\n",
    "\n",
    "   (c) By 5-NN?\n",
    "\n",
    "   **Solution:** \n",
    "\n",
    "   From $Table 1$ The five closest elements to point $p$ are $\\star_{(4,4)}$ ,$\\blacksquare_{(2,4)}$ , $\\blacksquare_{(4,6)}$, $\\star_{(2,6)}$ , and $\\blacksquare_{(4,2)}$ or $\\blacksquare_{(6,4)}$ . The frequency counts are as follows: $\\blacksquare : 3$ and $\\star : 2$.\n",
    "\n",
    "   $\\therefore$ the point $p$ will be classified as a square ($\\blacksquare$) by 5-NN.\n",
    "\n",
    "6. We decide to use 4-fold cross-validation to figure out the right value of $k$ to choose when running $k$-nearest neighbor on a data set of size 10,000. When checking a particular value of $k$, we look at four different training sets. What is the size of each of these training sets?\n",
    "\n",
    "**Solution:** \n",
    "\n",
    "Given: $k=4$ , $n=10000$\n",
    "\n",
    "Calculate the size of each fold ($f_s$).\n",
    "\n",
    "$f_s = \\frac{n}{k} = \\frac{10000}{4} = 2500$\n",
    "\n",
    "Hence, the size of each fold is $2500$\n",
    "\n",
    "Now, we will solve for the size of each training set ($t_s$) using the equation below:\n",
    "\n",
    "$$t_s = (k-1)\\times f_s$$\n",
    "\n",
    "Calculate the size of each training set such that $f_s=2500$ and $k=4$.\n",
    "\n",
    "$t_s = (k-1)\\times f_s = (4-1) \\times 2500 = 7500$\n",
    "\n",
    "$\\therefore$ the size of each training set is $7500$\n",
    "\n",
    "7. An extremal type of cross-validation is $n$-fold cross-validation on a training set of size $n$. If we want to estimate the error of $k$-NN, this amounts to classifying each training point by running $k$-NN on the remaining $n-1$ points, and then looking at the fraction of mistakes made. It is commonly called leave-one-out cross-validation (LOOCV).\n",
    "\n",
    "Consider the following simple data set of just four points:\n",
    "\n",
    "<center>\n",
    "\n",
    "   ![Simple Data Set](dsc_255_hw1_7.png)\n",
    "\n",
    "</center>\n",
    "\n",
    "What is the LOOCV error for 1-NN? For 3-NN?\n",
    "\n",
    "**Solution**\n",
    "\n",
    "Let the points seen above be defined as the following:\n",
    "\n",
    "$$p_1 = +$$\n",
    "$$p_2 = +$$\n",
    "$$p_3 = -$$\n",
    "$$p_4 = +$$\n",
    "\n",
    "Each $p_i$ for 1-NN would be classified as follows\n",
    "\n",
    "<center>\n",
    "\n",
    "| Point | Nearest Neighbor| Classification | Prediction |\n",
    "| :-------------: | :------------: | :-----------: |:-----------: |\n",
    "| $p_1(+)$ | $p_2(+)$    | $+$ | $True$ |\n",
    "| $p_2(+)$ | $p_1(+)$    | $+$ | $True$ |\n",
    "| $p_3(-)$ | $p_4(+)$    | $+$ | $False$ |\n",
    "| $p_4(+)$ | $p_3(-)$    | $-$ | $False$ |\n",
    "\n",
    "</center>\n",
    "\n",
    "From the table above we have two correct predictions for the four points or an accuracy of $50$%.\n",
    "\n",
    "Now , calculate LOOCV error ($LOOCV_{error}$)\n",
    "\n",
    "$LOOCV_{error} = 1 - accuracy = 1 - 0.50 = 0.50$\n",
    "\n",
    "$\\therefore$ LOOCV error for 1-NN is $50$%.\n",
    "\n",
    "Each $p_i$ for 3-NN would be classified as follows\n",
    "\n",
    "<center>\n",
    "\n",
    "| Point | Nearest Neighbors | Majority | Classification | Prediction | \n",
    "| :-------------: | :------------: | :-----------: | :-----------: | :-----------: |\n",
    "| $p_1(+)$ | $p_2(+)$ , $p_3(-)$ , $p_4(+)$ | $+$ | $+$ | $True$ |\n",
    "| $p_2(+)$ | $p_1(+)$ , $p_3(-)$ , $p_4(+)$ | $+$ | $+$ | $True$ |\n",
    "| $p_3(-)$ | $p_1(+)$ , $p_2(+)$ , $p_4(+)$ | $+$ | $+$ | $False$ |\n",
    "| $p_4(+)$ | $p_1(+)$ , $p_2(+)$ , $p_3(-)$ | $+$ | $+$ | $True$ |\n",
    "\n",
    "</center>\n",
    "\n",
    "From the table above we have three correct predictions for the four points\n",
    "\n",
    "Now , calculate LOOCV error ($LOOCV_{error}$)\n",
    "\n",
    "$LOOCV_{error} = 1 - accuracy = 1 - 0.75 = 0.25$\n",
    "\n",
    "$\\therefore$ LOOCV error for 3-NN is $25$%.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "### Programming Exercises\n",
    "\n",
    "Before attempting this problem, make sure that Python 3 and Jupyter are installed on your computer.\n",
    "\n",
    "8. **Nearest neighbor on MNIST.** For this problem, download the archive `hw1.zip`, available from the course website, and open it. The Jupyter notebook `nn-mnist.ipynb` implements a basic 1-NN classifier for a subset of the MNIST data set. It uses a separate training and test set. Begin by going through this notebook, running each segment and taking care to understand exactly what each line is doing.\n",
    "\n",
    "   Now do the following:\n",
    "   (a) For test point 100, print its image as well as the image of its nearest neighbor in the training set. Put these images in your writeup. Is this test point classified correctly?\n",
    "   (b) The confusion matrix for the classifier is a $10 \\times 10$ matrix $N_{ij}$ with $0 \\leq i, j \\leq 9$, where $N_{ij}$ is the number of test points whose true label is $i$ but which are classified as $j$. Thus, if all test points are correctly classified, the off-diagonal entries of the matrix will be zero.\n",
    "\n",
    "   - Compute the matrix $N$ for the 1-NN classifier and print it out.\n",
    "   - Which digit is misclassified most often? Least often?\n",
    "\n",
    "   (c) For each digit $0 \\leq i \\leq 9$: look at all training instances of image $i$, and compute their mean. This average is a 784-dimensional vector. Use the `show_digit` routine to print out these 10 average-digits.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
